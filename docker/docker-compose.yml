services:
  redis:
    image: redis:7-alpine
    container_name: llm-redis
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
      - ./redis.conf:/usr/local/etc/redis/redis.conf:ro
    command: redis-server /usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - llm_network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true

  llm-api:
    build: 
      context: ..
      dockerfile: docker/Dockerfile
      target: production
    container_name: llm-api
    ports:
      - "${API_PORT:-8000}:8000"
    env_file:
      - ../.env
    environment:
      # Override .env for container networking
      - REDIS_URL=redis://redis:6379/${REDIS_DB:-0}
      - REDIS_HOST=redis
    volumes:
      - ./models:/app/models:ro
      - ./logs:/app/logs
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - llm_network
    deploy:
      resources:
        limits:
          memory: ${MEMORY_LIMIT:-8G}
        reservations:
          memory: ${MEMORY_RESERVATION:-4G}
          devices:
            - driver: nvidia
              count: ${GPU_COUNT:-1}
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 90s
    logging:
      driver: "json-file"
      options:
        max-size: "25m"
        max-file: "5"
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:rw,noexec,nosuid,size=100m

networks:
  llm_network:
    driver: bridge
    name: llm_network

volumes:
  redis_data:
    name: llm_redis_data
