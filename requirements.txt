llama-cpp-python[cuda]==0.2.20
fastapi==0.104.1
uvicorn[standard]==0.24.0
redis==5.0.1
pydantic==2.5.0
python-multipart==0.0.6
transformers==4.53.0
accelerate==0.25.0
huggingface-hub==0.19.4
torch==2.1.1
sse-starlette==1.6.5
