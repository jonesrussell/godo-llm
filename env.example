# =============================================================================
# LLM API Configuration
# =============================================================================

# Hugging Face Configuration
HUGGINGFACE_HUB_TOKEN=my_secret_token

# Model Configuration
MODELS_DIR=models
MODEL_PATH=models/llama2-7b-q4.gguf
MODEL_CONTEXT_SIZE=2048
MODEL_BATCH_SIZE=512
GPU_LAYERS=20
GPU_COUNT=1

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_URL=redis://localhost:6379/0

# Performance Configuration
MAX_TOKENS_DEFAULT=256
TEMPERATURE_DEFAULT=0.7
TOP_P_DEFAULT=0.9
TOP_K_DEFAULT=40

# Resource Limits (Docker Compose)
MEMORY_LIMIT=8G
MEMORY_RESERVATION=4G

# Logging Configuration
LOG_LEVEL=INFO
LOG_FILE=logs/api.log

# Development Configuration
DEBUG=false
RELOAD=false

# Security Configuration
# Add any API keys or sensitive config here
# These will be loaded by the application and Docker Compose
