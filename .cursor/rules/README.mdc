---
alwaysApply: true
description: Overview of Cursor Rules for LLM inference pipeline project
---

# Cursor Rules Overview

This project includes comprehensive Cursor Rules to guide development of the Local LLM Inference Pipeline. These rules help maintain code quality, consistency, and best practices across the entire project.

## Available Rules

### üèóÔ∏è Project Structure & Architecture
- **[project-structure.mdc](mdc:.cursor/rules/project-structure.mdc)** - Project overview, file organization, and architecture guide
- **Always Applied** - Provides context for all development work

### üêç Python Development
- **[python-standards.mdc](mdc:.cursor/rules/python-standards.mdc)** - Python coding standards, type hints, async programming
- **Applies to**: `*.py` files
- **Covers**: Code style, imports, error handling, performance optimization

### üöÄ FastAPI Development
- **[fastapi-guidelines.mdc](mdc:.cursor/rules/fastapi-guidelines.mdc)** - FastAPI best practices, API design, streaming
- **Applies to**: `*.py` files
- **Covers**: Endpoint design, SSE streaming, error handling, middleware

### üê≥ Docker & Deployment
- **[docker-deployment.mdc](mdc:.cursor/rules/docker-deployment.mdc)** - Docker best practices, multi-service setup
- **Applies to**: `Dockerfile`, `docker-compose.yml`, `*.dockerfile`
- **Covers**: Containerization, GPU support, health checks, production deployment

### ‚öôÔ∏è Environment Configuration
- **[environment-config.mdc](mdc:.cursor/rules/environment-config.mdc)** - Environment setup and configuration management
- **Manual Application** - Use when working with environment setup
- **Covers**: Environment variables, model configuration, troubleshooting

### üß™ Testing Guidelines
- **[testing-guidelines.mdc](mdc:.cursor/rules/testing-guidelines.mdc)** - Testing best practices and patterns
- **Applies to**: `test_*.py`, `*_test.py` files
- **Covers**: API testing, model testing, performance testing, CI/CD

### üé® Frontend Development
- **[frontend-guidelines.mdc](mdc:.cursor/rules/frontend-guidelines.mdc)** - Vue.js development and API integration
- **Applies to**: `frontend/*.html`, `frontend/*.js`, `frontend/*.vue`
- **Covers**: Vue.js patterns, API integration, UI/UX, accessibility

## How to Use These Rules

### Automatic Application
Some rules are automatically applied:
- **Project Structure** - Always provides context
- **Python Standards** - Applied to all Python files
- **FastAPI Guidelines** - Applied to Python files
- **Docker Guidelines** - Applied to Docker files
- **Testing Guidelines** - Applied to test files
- **Frontend Guidelines** - Applied to frontend files

### Manual Application
Some rules require manual activation:
- **Environment Configuration** - Use when setting up or troubleshooting environment

### Rule Interactions
Rules work together to provide comprehensive guidance:
- Project structure provides overall context
- Language-specific rules (Python, FastAPI) provide detailed coding standards
- Infrastructure rules (Docker, Environment) guide deployment
- Testing and frontend rules ensure quality and user experience

## Key Project Information

### Technology Stack
- **Backend**: FastAPI with llama-cpp-python
- **Frontend**: Vue.js 3 with modern CSS
- **Caching**: Redis (optional)
- **Deployment**: Docker with GPU support
- **Model**: Llama-2-7b with Q4_K_M quantization

### Performance Targets
- **Hardware**: RTX 4060 (8GB VRAM)
- **Speed**: 15-20 tokens/second
- **Latency**: 50-80ms per token
- **Memory**: ~6GB VRAM usage

### Development Workflow
1. **Setup**: Use `setup_env.py`, `setup_model.py`, `setup_environment.sh`
2. **Development**: Follow Python and FastAPI guidelines
3. **Testing**: Use comprehensive test suite in `test_api.py`
4. **Frontend**: Develop Vue.js interface following frontend guidelines
5. **Deployment**: Use Docker Compose for multi-service deployment

## Getting Started

1. **Read Project Structure**: Understand the overall architecture
2. **Follow Python Standards**: Maintain code quality and consistency
3. **Use FastAPI Guidelines**: Build robust API endpoints
4. **Configure Environment**: Set up development environment properly
5. **Test Thoroughly**: Ensure reliability with comprehensive tests
6. **Deploy with Docker**: Use containerized deployment for production

These rules ensure consistent, high-quality development across the entire LLM inference pipeline project.