---
alwaysApply: true
description: Project structure and architecture guide for the Local LLM Inference Pipeline
---

# Project Structure Guide

This is a **Local LLM Inference Pipeline** built with FastAPI, featuring Llama-2-7b inference on RTX 4060 with Redis caching and Vue.js frontend.

## Core Architecture

- **Main Entry Point**: [main.py](mdc:main.py) - FastAPI application with streaming LLM inference
- **Task Automation**: [Taskfile.yml](mdc:Taskfile.yml) - Complete task automation for setup, testing, and deployment
- **Model Setup**: [setup_model.py](mdc:setup_model.py) - Automated model download with fallbacks
- **Environment Setup**: [setup_env.py](mdc:setup_env.py) - System dependencies and environment configuration
- **Testing Suite**: [test_api.py](mdc:test_api.py) - Comprehensive API testing

## Key Directories

- **docker/**: Multi-service Docker deployment with Redis caching
  - [docker-compose.yml](mdc:docker/docker-compose.yml) - Main service orchestration
  - [Dockerfile](mdc:docker/Dockerfile) - Container configuration
- **frontend/**: Vue.js web interface
  - [index.html](mdc:frontend/index.html) - Single-page application
- **venv/**: Python virtual environment (auto-created)
- **models/**: Downloaded LLM models (auto-created)

## Technology Stack

- **Backend**: FastAPI with async/await patterns
- **LLM**: llama-cpp-python with CUDA support
- **Caching**: Redis with async support
- **Frontend**: Vue.js with Server-Sent Events
- **Deployment**: Docker Compose with multi-service setup
- **Task Management**: Task (taskfile.dev) for automation

## Development Workflow

1. Use `task` commands for all operations (see [Taskfile.yml](mdc:Taskfile.yml))
2. Environment setup: `task setup`
3. Start services: `task start`
4. Run tests: `task test`
5. Docker deployment: `task docker:up`

## Performance Characteristics

- **Target Hardware**: NVIDIA RTX 4060 (8GB VRAM)
- **Performance**: ~5.4 tokens/sec verified
- **Caching**: 209x speed improvement on repeated requests
- **Streaming**: Real-time token generation via Server-Sent Events